{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94910989-2db2-4cd6-baa6-7ca1a3567da6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üöÄ Databricks Getting Started - Essential Demos Installation\n",
    "\n",
    "Welcome to Databricks! This notebook will help you get started by installing and exploring the most important demos that showcase key platform capabilities.\n",
    "\n",
    "## What You'll Install\n",
    "\n",
    "This notebook installs 7 essential **dbdemos** that every new Databricks user should explore:\n",
    "\n",
    "* **Delta Lake** - Learn about the foundation of the Databricks Lakehouse with ACID transactions, time travel, and data versioning\n",
    "* **Auto Loader** - Master incremental data ingestion from cloud storage with automatic schema evolution\n",
    "* **Unity Catalog Data Lineage** - Understand data governance, lineage tracking, and metadata management\n",
    "* **Delta Sharing Airlines** - Explore secure data sharing across organizations without copying data\n",
    "* **Delta Live Tables Pipeline** - Build reliable data pipelines with declarative ETL\n",
    "* **AI/BI Portfolio Assistant** - Explore advanced analytics and AI capabilities with dashboards and Genie\n",
    "* **SQL Warehouse** - Understand data warehousing features including identity columns, primary/foreign keys, and stored procedures\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Databricks workspace access\n",
    "* Cluster with appropriate permissions\n",
    "* Internet connectivity for package installation\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. Click the \"Run All\" command in the top right of the notebook\n",
    "2. Each demo installation may take 2-5 minutes\n",
    "3. After installation, explore the generated folders in your workspace\n",
    "4. Follow the README files in each demo folder for detailed walkthroughs\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Note**: Demo installations will create new folders, tables, and resources in your workspace. Make sure you have sufficient permissions and storage quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31b6c579-60c9-42c9-a2a6-243d2816d953",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install dbdemos Package"
    }
   },
   "outputs": [],
   "source": [
    "# Install the dbdemos package\n",
    "# This package provides pre-built demos showcasing Databricks capabilities\n",
    "%pip install dbdemos --quiet\n",
    "\n",
    "# Restart Python to ensure the package is properly loaded\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40994e07-ddf0-4f0f-ab30-89729db0fc5a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import dbdemos and Check Version"
    }
   },
   "outputs": [],
   "source": [
    "import dbdemos\n",
    "\n",
    "# Display dbdemos version and available demos\n",
    "print(f\"dbdemos version: {dbdemos.__version__}\")\n",
    "print(\"\\nüìã Installing 7 essential demos for new Databricks users...\")\n",
    "print(\"Each installation may take 2-5 minutes depending on demo complexity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd4e465-285f-4374-9345-55257ad50ee5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üèóÔ∏è Demo 1: Delta Lake - The Foundation of Databricks Lakehouse\n",
    "\n",
    "**Delta Lake** is the storage layer that brings ACID transactions to Apache Spark and big data workloads.\n",
    "\n",
    "### What you'll learn:\n",
    "* ACID transactions for data reliability\n",
    "* Time travel and data versioning\n",
    "* Schema enforcement and evolution\n",
    "* Optimizations like Z-ordering and auto-compaction\n",
    "* Streaming and batch data processing\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Creating Delta tables\n",
    "* Handling schema changes\n",
    "* Time travel queries\n",
    "* Merge operations (UPSERT)\n",
    "* Performance optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817c085a-00f9-4816-904e-b1cf7c3da827",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Delta Lake Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install Delta Lake demo\n",
    "print(\"üîÑ Installing Delta Lake demo...\")\n",
    "dbdemos.install('delta-lake')\n",
    "print(\"‚úÖ Delta Lake demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'delta-lake' folder in your workspace for notebooks and datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc09a88c-00b4-4e73-b944-f39ace689b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì• Demo 2: Auto Loader - Incremental Data Ingestion\n",
    "\n",
    "**Auto Loader** incrementally and efficiently processes new data files as they arrive in cloud storage.\n",
    "\n",
    "### What you'll learn:\n",
    "* Setting up Auto Loader for various file formats\n",
    "* Automatic schema inference and evolution\n",
    "* Handling bad records and data quality\n",
    "* Monitoring and alerting\n",
    "* Integration with Delta Live Tables\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Cloud file ingestion (S3, ADLS, GCS)\n",
    "* Schema evolution handling\n",
    "* Checkpointing and exactly-once processing\n",
    "* Error handling and dead letter queues\n",
    "* Performance optimization **techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fdeb2b1-eb89-4f63-b52c-f0d8652f7123",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Auto Loader Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install Auto Loader demo\n",
    "print(\"üîÑ Installing Auto Loader demo...\")\n",
    "dbdemos.install('auto-loader')\n",
    "print(\"‚úÖ Auto Loader demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'auto-loader' folder in your workspace for ingestion patterns and examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feff1e64-b9ed-4b8d-9a46-a0a7fa5d02ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Demo 3: Unity Catalog Data Lineage - Data Governance"
    }
   },
   "source": [
    "## üìà Demo 3: Unity Catalog Data Lineage - Data Governance & Metadata Management\n",
    "\n",
    "**Unity Catalog** provides centralized governance, security, and lineage tracking across your data estate.\n",
    "\n",
    "### What you'll learn:\n",
    "* Data governance and access control\n",
    "* Automatic lineage tracking and visualization\n",
    "* Metadata management and discovery\n",
    "* Cross-workspace data sharing\n",
    "* Audit logging and compliance\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Catalog and schema management\n",
    "* Table and column-level lineage\n",
    "* Data discovery and search\n",
    "* Access control policies\n",
    "* Audit trail and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df31d63-e0bc-4dfd-99d1-0b7ccbfe8f88",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Unity Catalog Data Lineage Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install Unity Catalog Data Lineage demo\n",
    "print(\"üîÑ Installing Unity Catalog Data Lineage demo...\")\n",
    "dbdemos.install('uc-03-data-lineage')\n",
    "print(\"‚úÖ Unity Catalog Data Lineage demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'uc-03-data-lineage' folder for governance and lineage examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa15d732-7532-4766-b694-ddb3987f70b0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Demo 4: Delta Sharing Airlines - Secure Data Sharing"
    }
   },
   "source": [
    "## ‚úàÔ∏è Demo 4: Delta Sharing Airlines - Secure Cross-Organization Data Sharing\n",
    "\n",
    "**Delta Sharing** enables secure data sharing across organizations without copying data, using an open protocol.\n",
    "\n",
    "### What you'll learn:\n",
    "* Setting up Delta Sharing providers and recipients\n",
    "* Sharing live data across organizations securely\n",
    "* Managing data sharing permissions and access\n",
    "* Working with shared datasets in real-time\n",
    "* Cross-platform data collaboration\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Creating and managing data shares\n",
    "* Recipient access and authentication\n",
    "* Real-time data access without copying\n",
    "* Cross-cloud and cross-platform sharing\n",
    "* Audit and monitoring of shared data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbff18f0-822f-405f-a563-1dcafdea3c4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Delta Sharing Airlines Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install Delta Sharing Airlines demo\n",
    "print(\"üîÑ Installing Delta Sharing Airlines demo...\")\n",
    "dbdemos.install('delta-sharing-airlines', overwrite=True)\n",
    "print(\"‚úÖ Delta Sharing Airlines demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'delta-sharing-airlines' folder for data sharing examples and configurations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3bf77cb-7d2b-4eae-bd92-62fe12e680ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Demo 5: Delta Live Tables Pipeline - Reliable ETL"
    }
   },
   "source": [
    "## üîÑ Demo 5: Delta Live Tables Pipeline - Declarative ETL Pipelines\n",
    "\n",
    "**Delta Live Tables (DLT)** simplifies building reliable, maintainable, and testable data processing pipelines.\n",
    "\n",
    "### What you'll learn:\n",
    "* Declarative pipeline development\n",
    "* Automatic data quality monitoring\n",
    "* Pipeline orchestration and scheduling\n",
    "* Error handling and recovery\n",
    "* Live table and streaming table patterns\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Creating live tables and streaming tables\n",
    "* Data quality constraints and expectations\n",
    "* Pipeline dependency management\n",
    "* Automatic schema evolution\n",
    "* Monitoring and observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae59934d-0965-4772-919c-ae7417a82d0e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Delta Live Tables Pipeline Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install Delta Live Tables Pipeline demo with custom catalog and schema\n",
    "print(\"üîÑ Installing Delta Live Tables Pipeline demo...\")\n",
    "dbdemos.install('pipeline-bike', catalog='main', schema='dbdemos_pipeline_bike', overwrite=True)\n",
    "print(\"‚úÖ Delta Live Tables Pipeline demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'pipeline-bike' folder for DLT pipeline examples and configurations.\")\n",
    "print(\"üóÑÔ∏è Data stored in: main.dbdemos_pipeline_bike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78e5830-7d9c-46e4-98bf-8fd54b2735c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ü§ñ Demo 6: AI/BI Portfolio Assistant - Advanced Analytics & AI\n",
    "\n",
    "**Databricks AI/BI** combines the power of AI with business intelligence for advanced analytics in capital markets.\n",
    "\n",
    "### What you'll learn:\n",
    "* Building AI-powered dashboards\n",
    "* Using Genie for natural language queries\n",
    "* Financial data analysis and modeling\n",
    "* Real-time portfolio monitoring\n",
    "* Advanced visualization techniques\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* AI-assisted data exploration\n",
    "* Natural language to SQL with Genie\n",
    "* Interactive dashboards\n",
    "* Financial risk modeling\n",
    "* Automated insights and alerts\n",
    "\n",
    "**Note**: This demo uses a custom catalog and schema for financial services data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da66102-53c6-413f-a3f7-bf8d147ee8e0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Unity Catalog Data Lineage Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install AI/BI Portfolio Assistant demo with custom catalog and schema\n",
    "print(\"üîÑ Installing AI/BI Portfolio Assistant demo...\")\n",
    "dbdemos.install('aibi-portfolio-assistant', catalog='main', schema='dbdemos_aibi_fsi_portfolio_assistant', overwrite=True)\n",
    "print(\"‚úÖ AI/BI Portfolio Assistant demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'aibi-portfolio-assistant' folder for dashboards and AI-powered analytics.\")\n",
    "print(\"üóÑÔ∏è Data stored in: main.dbdemos_aibi_fsi_portfolio_assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5663b7f-b8a6-4e17-a533-bcac09ec21d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üè¢ Demo 7: SQL Warehouse - Enterprise Data Warehousing\n",
    "\n",
    "**SQL Warehouse** demonstrates advanced data warehousing capabilities including modern SQL features and enterprise-grade functionality.\n",
    "\n",
    "### What you'll learn:\n",
    "* Identity columns and auto-incrementing keys\n",
    "* Primary and foreign key constraints\n",
    "* Stored procedures and functions\n",
    "* Control flow with loops and conditionals\n",
    "* Advanced SQL patterns and optimizations\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "* Table constraints and relationships\n",
    "* Stored procedure development\n",
    "* Transaction management\n",
    "* Performance tuning\n",
    "* Data governance and security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0799ee4-1048-4c72-8018-26819eefc215",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install SQL Warehouse Demo"
    }
   },
   "outputs": [],
   "source": [
    "# Install SQL Warehouse demo\n",
    "print(\"üîÑ Installing SQL Warehouse demo...\")\n",
    "dbdemos.install('sql-warehouse')\n",
    "print(\"‚úÖ SQL Warehouse demo installed successfully!\")\n",
    "print(\"üìÅ Check the 'sql-warehouse' folder for advanced SQL examples and stored procedures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ebb28a-801e-4d5a-b1d4-b87f7bfb5eb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üéâ Installation Complete!\n",
    "\n",
    "Congratulations! You've successfully installed 7 essential Databricks demos. Here's what to do next:\n",
    "\n",
    "## üìÇ Explore Your New Demo Folders\n",
    "\n",
    "Check your workspace for these new folders:\n",
    "* `delta-lake/` - Delta Lake fundamentals and advanced features\n",
    "* `auto-loader/` - Data ingestion patterns\n",
    "* `uc-03-data-lineage/` - Unity Catalog governance and lineage\n",
    "* `delta-sharing-airlines/` - Secure cross-organization data sharing\n",
    "* `pipeline-bike/` - Delta Live Tables declarative ETL pipelines\n",
    "* `aibi-portfolio-assistant/` - AI/BI analytics and dashboards\n",
    "* `sql-warehouse/` - Advanced SQL warehousing features\n",
    "\n",
    "## üöÄ Recommended Learning Path\n",
    "\n",
    "1. **Start with Delta Lake** - Understanding the storage foundation\n",
    "2. **Explore Auto Loader** - Learn data ingestion patterns\n",
    "3. **Understand Unity Catalog** - Data governance and lineage\n",
    "4. **Try Delta Sharing** - Secure data collaboration\n",
    "5. **Build with Delta Live Tables** - Reliable ETL pipelines\n",
    "6. **Experiment with SQL Warehouse** - Advanced SQL features\n",
    "7. **Dive into AI/BI** - Advanced analytics and AI capabilities\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "* [Databricks Documentation](https://docs.databricks.com/)\n",
    "* [Databricks Academy](https://www.databricks.com/learn/training/login)\n",
    "* [Community Forums](https://community.databricks.com/)\n",
    "* [GitHub Examples](https://github.com/databricks)\n",
    "\n",
    "## üí° Tips for Success\n",
    "\n",
    "* Each demo folder contains a README with detailed instructions\n",
    "* Start with the `00-` numbered notebooks in each folder\n",
    "* Don't hesitate to modify and experiment with the code\n",
    "* Join the Databricks community for support and best practices\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! üéì**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1. Getting Started",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
