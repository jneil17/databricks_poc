{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698b6c64-c1f2-483f-96e9-79f6773edc6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Getting Data Into Databricks\n",
    "\n",
    "Every data journey starts with ingestion. Databricks is an open platform that provides multiple ways to load your data, from simple point-and-click interfaces to automated, enterprise-grade tools. Let's explore three common methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Point-and-Click with Lakehouse Connect\n",
    "\n",
    "The easiest way to connect to hundreds of data sources is using the built-in connectors. This UI-driven approach is perfect for quickly loading data from external databases like MySQL, Postgres, Salesforce, and many more without writing code.\n",
    "\n",
    "The video below provides a fantastic overview of how to connect to sources using the UI.\n",
    "\n",
    "[![Video Thumbnail](https://img.youtube.com/vi/bQy_2vE_e-k/0.jpg)](https://www.youtube.com/watch?v=bQy_2vE_e-k \"Connecting to External Data in Databricks\")\n",
    "\n",
    "### To Try It Yourself:\n",
    "1. In the left navigation bar, click **+ New** > **Add data**.\n",
    "2. Click **Lakehouse Connect** to browse available sources.\n",
    "\n",
    "üìñ **Resource:** [Lakeflow Connect Documentation](https://docs.databricks.com/en/connect/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Partner Connect with Fivetran & Others\n",
    "\n",
    "Databricks partners with leading data integration companies like Fivetran, Airbyte, and Informatica. These partners provide pre-built, managed connectors for hundreds of SaaS applications (e.g., Google Analytics, Stripe, HubSpot).\n",
    "\n",
    "**Partner Connect** is a feature in the Databricks UI that simplifies the process of connecting these tools to your workspace.\n",
    "\n",
    "### To Explore:\n",
    "1. In the left navigation bar, go to **Partner Connect**.\n",
    "2. Find a data integration partner like **Fivetran** and follow the on-screen steps to connect.\n",
    "\n",
    "üìñ **Resource:** [Partner Connect Documentation](https://docs.databricks.com/en/partner-connect/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Automated Ingestion with Auto Loader\n",
    "\n",
    "For data landing in cloud storage (S3, ADLS, GCS), **Auto Loader** is the most powerful and efficient tool. It automatically and incrementally processes new files as they arrive, handling schema changes and scalability for you. This is the recommended best practice for file-based ingestion.\n",
    "\n",
    "Your setup script installed the `auto-loader` demo, which provides a hands-on example.\n",
    "\n",
    "### To See it in Action:\n",
    "\n",
    "Navigate to the `auto-loader` demo folder in your workspace and open the **`01-Auto-Loader-and-Schema-Evolution`** notebook. This notebook shows how you can easily ingest files with just a few lines of SQL or Python.\n",
    "\n",
    "[![Video Thumbnail](https://img.youtube.com/vi/iRedJ21aH-E/0.jpg)](https://www.youtube.com/watch?v=iRedJ21aH-E \"What is Auto Loader?\")\n",
    "\n",
    "### üìñ Additional Resources:\n",
    "* [Auto Loader Documentation](https://docs.databricks.com/en/ingestion/auto-loader/index.html)\n",
    "* [Delta Lake Best Practices](https://www.databricks.com/blog/2021/07/28/data-lakehouse-foundational-data-warehousing-and-data-governance.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Code-Based Ingestion Examples\n",
    "\n",
    "For developers who prefer programmatic approaches, here are code examples for common ingestion patterns:\n",
    "\n",
    "### Reading from Cloud Storage (S3, ADLS, GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading CSV files from cloud storage\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3a://your-bucket/path/to/files/*.csv\")\n",
    "\n",
    "# Save to Delta table\n",
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"main.default.your_table_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Loader with SQL (Recommended for Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Auto Loader example: Automatically ingest new files as they arrive\n",
    "CREATE OR REFRESH STREAMING LIVE TABLE raw_data\n",
    "AS SELECT * FROM cloud_files(\n",
    "  \"s3://your-bucket/incoming-data/\", \n",
    "  \"json\",\n",
    "  map(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Resource Library\n",
    "\n",
    "### üìö **Official Documentation**\n",
    "* [Data Ingestion on Databricks - Complete Guide](https://docs.databricks.com/en/ingestion/index.html)\n",
    "* [Auto Loader Deep Dive](https://docs.databricks.com/en/ingestion/auto-loader/index.html)\n",
    "* [Partner Connect Documentation](https://docs.databricks.com/en/partner-connect/index.html)\n",
    "* [Lakehouse Connect (Data Connectors)](https://docs.databricks.com/en/connect/index.html)\n",
    "* [File Upload and Data Import](https://docs.databricks.com/en/ingestion/add-data/index.html)\n",
    "\n",
    "### üé• **Video Learning Resources**\n",
    "* [Data Ingestion Fundamentals Playlist](https://www.youtube.com/playlist?list=PLTPXxbhUt-YWSBvUOHEEhUTdCfpyZ1H_R)\n",
    "* [Auto Loader Best Practices](https://www.youtube.com/watch?v=iRedJ21aH-E)\n",
    "* [Connecting External Data Sources](https://www.youtube.com/watch?v=bQy_2vE_e-k)\n",
    "* [Streaming Data Ingestion](https://www.youtube.com/watch?v=KeCJ8Zm6xig)\n",
    "\n",
    "### üõ†Ô∏è **Hands-On Tutorials**\n",
    "* [Auto Loader Quickstart Tutorial](https://docs.databricks.com/en/ingestion/auto-loader/tutorial.html)\n",
    "* [Data Engineering with Databricks Course (Free)](https://academy.databricks.com/path/data-engineer)\n",
    "* [Ingestion Best Practices Workshop](https://github.com/databricks-academy/data-engineering-with-databricks)\n",
    "\n",
    "### üìñ **Advanced Reading**\n",
    "* [Schema Evolution in Auto Loader](https://docs.databricks.com/en/ingestion/auto-loader/schema.html)\n",
    "* [Performance Optimization for Data Ingestion](https://www.databricks.com/blog/2020/02/19/auto-loader-production-data-ingestion-made-easy.html)\n",
    "* [Multi-Cloud Data Ingestion Strategies](https://www.databricks.com/blog/2021/03/24/simplify-and-scale-data-ingestion-with-databricks-autoloader.html)\n",
    "* [Real-time Streaming Ingestion Patterns](https://docs.databricks.com/en/structured-streaming/index.html)\n",
    "\n",
    "### üîå **Partner Solutions**\n",
    "* [Fivetran Integration Guide](https://docs.databricks.com/en/partners/prep/fivetran.html)\n",
    "* [Airbyte Setup Instructions](https://docs.databricks.com/en/partners/prep/airbyte.html)\n",
    "* [Stitch Data Integration](https://docs.databricks.com/en/partners/prep/stitch.html)\n",
    "* [AWS DMS Integration](https://docs.databricks.com/en/connect/external-systems/aws-dms.html)\n",
    "\n",
    "### üèóÔ∏è **Architecture Patterns**\n",
    "* [Medallion Architecture for Data Ingestion](https://www.databricks.com/glossary/medallion-architecture)\n",
    "* [Lambda vs Kappa Architecture](https://www.databricks.com/blog/2021/08/30/frequently-asked-questions-about-the-databricks-lakehouse-platform.html)\n",
    "* [Data Mesh Implementation Patterns](https://www.databricks.com/solutions/accelerators/data-mesh)\n",
    "\n",
    "### üí° **Community Resources**\n",
    "* [Databricks Community Forums - Data Ingestion](https://community.databricks.com/s/topic/0TO0w000000MqzDGAS/data-ingestion)\n",
    "* [Stack Overflow - Databricks Ingestion Tags](https://stackoverflow.com/questions/tagged/databricks+data-ingestion)\n",
    "* [Reddit - r/databricks](https://www.reddit.com/r/databricks/)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. Data Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
