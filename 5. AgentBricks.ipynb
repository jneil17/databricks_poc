{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8e715a-f5c1-4336-8f23-f3d9970ecf30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Building with Generative AI: An Introduction to AgentBricks\n",
    "\n",
    "Databricks is the premier platform for building production-quality Generative AI applications. While AI/ML is a deep topic, this notebook will give you a high-level overview of **AgentBricks**, Databricks' framework and set of capabilities for building AI agents that can reason and use tools to accomplish complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "An AI Agent is a system that can understand a high-level goal, break it down into steps, and use tools (like querying a database, searching the web, or calling an API) to achieve that goal. The video below explains how Databricks makes this possible with your own enterprise data.\n",
    "\n",
    "[![Video Thumbnail](https://img.youtube.com/vi/a4XFm8tP_Lw/0.jpg)](https://www.youtube.com/watch?v=a4XFm8tP_Lw \"Building AI Agents on Databricks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common AI Agent Patterns to Explore\n",
    "\n",
    "Building a custom AI agent can be complex, so Databricks provides several pre-built patterns and capabilities that you can explore and customize.\n",
    "\n",
    "--- \n",
    "\n",
    "### 1. Knowledge Assistant (Retrieval-Augmented Generation - RAG)\n",
    "\n",
    "This is the most common pattern. A RAG agent can \"chat\" with your documents or structured data, providing answers grounded in your proprietary information. This is powered by **Databricks Vector Search**.\n",
    "\n",
    "üìñ **Resources:**\n",
    "* [Best Practices for RAG on Databricks](https://www.databricks.com/blog/2023/10/25/best-practices-for-llm-evaluation-of-rag-applications.html)\n",
    "* [Vector Search Documentation](https://docs.databricks.com/en/generative-ai/vector-search.html)\n",
    "\n",
    "--- \n",
    "\n",
    "### 2. Information Extraction Agent\n",
    "\n",
    "This agent can read unstructured documents (like PDFs, emails, or images) and extract structured data (like invoice numbers, dates, and amounts), saving it to a Delta table for analysis.\n",
    "\n",
    "üìñ **Resource:** [Intelligent Document Processing with Databricks](https://www.databricks.com/solutions/accelerators/intelligent-document-processing)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Custom LLMs (Finetuning)\n",
    "\n",
    "For advanced use cases, you can use the Finetuning API to adapt an open-source LLM on your private data. This creates a model that is an expert in your specific domain, using your company's terminology and style.\n",
    "\n",
    "üìñ **Resource:** [Finetuning API Documentation](https://docs.databricks.com/en/large-language-models/foundation-model-training/index.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to Go Next: Explore AgentBricks on GitHub\n",
    "\n",
    "The best way to get started with building agents is to explore the official **AgentBricks repository on GitHub**. It provides hands-on examples, labs, and tutorials for the patterns discussed above.\n",
    "\n",
    "### ‚û°Ô∏è [**Click here to visit the AgentBricks GitHub Repository**](https://github.com/databricks/agentbricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Code Examples\n",
    "\n",
    "### Simple RAG Implementation with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Building a simple knowledge assistant with Vector Search\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import openai\n",
    "\n",
    "# Initialize clients\n",
    "vsc = VectorSearchClient()\n",
    "workspace = WorkspaceClient()\n",
    "\n",
    "# Create a vector search index for your documents\n",
    "def create_knowledge_base(catalog, schema, table_name):\n",
    "    \"\"\"\n",
    "    Create a vector search index for document embeddings\n",
    "    \"\"\"\n",
    "    index = vsc.create_delta_sync_index(\n",
    "        endpoint_name=\"your_vector_search_endpoint\",\n",
    "        index_name=f\"{catalog}.{schema}.{table_name}_index\",\n",
    "        source_table_name=f\"{catalog}.{schema}.{table_name}\",\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"id\",\n",
    "        embedding_source_column=\"text\",\n",
    "        embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    "    )\n",
    "    return index\n",
    "\n",
    "# Search for relevant context\n",
    "def search_knowledge_base(query, index_name, k=5):\n",
    "    \"\"\"\n",
    "    Search for relevant documents based on user query\n",
    "    \"\"\"\n",
    "    results = vsc.similarity_search(\n",
    "        index_name=index_name,\n",
    "        query_text=query,\n",
    "        columns=[\"text\", \"metadata\"],\n",
    "        num_results=k\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Generate response using RAG pattern\n",
    "def generate_response(user_query, context_docs):\n",
    "    \"\"\"\n",
    "    Generate a response using retrieved context\n",
    "    \"\"\"\n",
    "    context = \"\\n\".join([doc[\"text\"] for doc in context_docs])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the following context, answer the user's question:\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {user_query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using Foundation Model API\n",
    "    response = workspace.serving_endpoints.query(\n",
    "        name=\"databricks-llama-2-70b-chat\",\n",
    "        dataframe_records=[{\"prompt\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.predictions[0]\n",
    "\n",
    "# Example usage\n",
    "# query = \"What are the best practices for data engineering?\"\n",
    "# docs = search_knowledge_base(query, \"main.knowledge.docs_index\")\n",
    "# answer = generate_response(query, docs)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Agent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Agent with function calling capabilities\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "class DataAnalysisAgent:\n",
    "    \"\"\"\n",
    "    An agent that can analyze data using various tools\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, workspace_client):\n",
    "        self.workspace = workspace_client\n",
    "        self.available_functions = {\n",
    "            \"run_sql_query\": self.run_sql_query,\n",
    "            \"create_visualization\": self.create_visualization,\n",
    "            \"get_table_schema\": self.get_table_schema\n",
    "        }\n",
    "    \n",
    "    def run_sql_query(self, query: str) -> Dict:\n",
    "        \"\"\"Execute SQL query and return results\"\"\"\n",
    "        try:\n",
    "            result = spark.sql(query).toPandas()\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"data\": result.to_dict('records'),\n",
    "                \"row_count\": len(result)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    def create_visualization(self, data_query: str, chart_type: str = \"bar\") -> Dict:\n",
    "        \"\"\"Create a visualization from data\"\"\"\n",
    "        # This would integrate with plotting libraries\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"chart_type\": chart_type,\n",
    "            \"message\": f\"Created {chart_type} chart for query: {data_query}\"\n",
    "        }\n",
    "    \n",
    "    def get_table_schema(self, table_name: str) -> Dict:\n",
    "        \"\"\"Get schema information for a table\"\"\"\n",
    "        try:\n",
    "            schema = spark.table(table_name).schema\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"schema\": str(schema),\n",
    "                \"columns\": [field.name for field in schema.fields]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    def process_request(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Process user request and determine which functions to call\n",
    "        \"\"\"\n",
    "        # This would use an LLM to determine function calls\n",
    "        # For demo purposes, we'll use simple logic\n",
    "        \n",
    "        if \"schema\" in user_message.lower():\n",
    "            # Extract table name and get schema\n",
    "            table_name = \"main.dbdemos_pipeline_bike.bike_trips_gold\"  # example\n",
    "            result = self.get_table_schema(table_name)\n",
    "            return f\"Table schema: {result}\"\n",
    "        \n",
    "        elif \"query\" in user_message.lower() or \"sql\" in user_message.lower():\n",
    "            # Execute a sample query\n",
    "            query = \"SELECT user_type, COUNT(*) as count FROM main.dbdemos_pipeline_bike.bike_trips_gold GROUP BY user_type LIMIT 10\"\n",
    "            result = self.run_sql_query(query)\n",
    "            return f\"Query results: {result}\"\n",
    "        \n",
    "        else:\n",
    "            return \"I can help you with SQL queries, table schemas, and visualizations. What would you like to explore?\"\n",
    "\n",
    "# Example usage\n",
    "# agent = DataAnalysisAgent(workspace)\n",
    "# response = agent.process_request(\"Show me the schema for the bike trips table\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Resource Library\n",
    "\n",
    "### üìö **Official Documentation**\n",
    "* [Generative AI on Databricks - Complete Guide](https://docs.databricks.com/en/generative-ai/index.html)\n",
    "* [Vector Search Documentation](https://docs.databricks.com/en/generative-ai/vector-search.html)\n",
    "* [Foundation Model APIs](https://docs.databricks.com/en/machine-learning/foundation-models/index.html)\n",
    "* [Model Serving for AI Applications](https://docs.databricks.com/en/machine-learning/model-serving/index.html)\n",
    "* [Fine-tuning LLMs](https://docs.databricks.com/en/large-language-models/foundation-model-training/index.html)\n",
    "* [MLflow for GenAI](https://docs.databricks.com/en/mlflow/llms/index.html)\n",
    "\n",
    "### üé• **Video Learning Resources**\n",
    "* [Building AI Agents on Databricks](https://www.youtube.com/watch?v=a4XFm8tP_Lw)\n",
    "* [RAG with Vector Search Deep Dive](https://www.youtube.com/watch?v=LWt41AkdqTU)\n",
    "* [LLM Fine-tuning Masterclass](https://www.youtube.com/watch?v=IyF_oN_rr7s)\n",
    "* [GenAI Application Development](https://www.youtube.com/watch?v=nvn2JDYfP-Q)\n",
    "* [AI Function Calling Tutorial](https://www.youtube.com/watch?v=P7FvBh2C82E)\n",
    "* [Production GenAI with Databricks](https://www.youtube.com/watch?v=K0CFhXq3ZdM)\n",
    "\n",
    "### üõ†Ô∏è **Hands-On Tutorials and Labs**\n",
    "* [RAG Application Tutorial](https://docs.databricks.com/en/generative-ai/tutorials/ai-cookbook/index.html)\n",
    "* [Building AI Agents Workshop](https://github.com/databricks/agentbricks)\n",
    "* [Vector Search Quickstart](https://docs.databricks.com/en/generative-ai/vector-search-quickstart.html)\n",
    "* [LLM Evaluation Framework](https://docs.databricks.com/en/machine-learning/model-evaluation/index.html)\n",
    "* [Generative AI Academy Course](https://academy.databricks.com/path/generative-ai-engineer)\n",
    "\n",
    "### üìñ **Advanced Reading and Research**\n",
    "* [RAG Best Practices Guide](https://www.databricks.com/blog/2023/10/25/best-practices-for-llm-evaluation-of-rag-applications.html)\n",
    "* [LLM Evaluation Strategies](https://www.databricks.com/blog/2023/08/31/llm-evaluation-with-mlflow.html)\n",
    "* [Production GenAI Architecture](https://www.databricks.com/blog/2023/07/20/announcing-mlflow-26-and-llm-evaluation.html)\n",
    "* [Advanced Prompting Techniques](https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html)\n",
    "* [Agent Framework Design Patterns](https://www.databricks.com/blog/2023/06/20/generative-ai-agent-guide.html)\n",
    "\n",
    "### üèóÔ∏è **Architecture and Implementation Patterns**\n",
    "* [Enterprise RAG Architecture](https://www.databricks.com/solutions/accelerators/retrieval-augmented-generation)\n",
    "* [Multi-Modal AI Applications](https://www.databricks.com/blog/2023/08/30/building-multimodal-ai-applications-databricks.html)\n",
    "* [Conversation AI Systems](https://www.databricks.com/solutions/accelerators/conversational-ai)\n",
    "* [Document Intelligence Patterns](https://www.databricks.com/solutions/accelerators/intelligent-document-processing)\n",
    "* [Real-time AI Agent Deployment](https://docs.databricks.com/en/machine-learning/model-serving/create-manage-serving-endpoints.html)\n",
    "\n",
    "### üß† **Model and Framework Libraries**\n",
    "* **AgentBricks (Official):**\n",
    "  - [GitHub Repository](https://github.com/databricks/agentbricks)\n",
    "  - [Documentation](https://agentbricks.readthedocs.io/)\n",
    "* **LangChain Integration:**\n",
    "  - [LangChain with Databricks](https://python.langchain.com/docs/integrations/platforms/databricks)\n",
    "  - [Vector Store Integration](https://python.langchain.com/docs/integrations/vectorstores/databricks_vector_search)\n",
    "* **LlamaIndex Integration:**\n",
    "  - [LlamaIndex Databricks Connector](https://docs.llamaindex.ai/en/stable/examples/vector_stores/DatabricksVectorSearch.html)\n",
    "* **Hugging Face Integration:**\n",
    "  - [Hugging Face on Databricks](https://docs.databricks.com/en/machine-learning/train-model/huggingface.html)\n",
    "\n",
    "### üîß **Development Tools and SDKs**\n",
    "* [Databricks SDK for Python](https://databricks-sdk-py.readthedocs.io/)\n",
    "* [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)\n",
    "* [Vector Search Client SDK](https://docs.databricks.com/en/generative-ai/vector-search-client.html)\n",
    "* [Model Serving APIs](https://docs.databricks.com/en/dev-tools/api/latest/serving-endpoints.html)\n",
    "* [CLI Tools for GenAI](https://docs.databricks.com/en/dev-tools/cli/index.html)\n",
    "\n",
    "### üß™ **Testing and Evaluation**\n",
    "* [LLM Evaluation with MLflow](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html)\n",
    "* [A/B Testing for AI Models](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-intro.html)\n",
    "* [Monitoring GenAI Applications](https://docs.databricks.com/en/machine-learning/model-serving/monitor-serving-endpoints.html)\n",
    "* [Responsible AI Practices](https://docs.databricks.com/en/machine-learning/model-evaluation/evaluation-suite.html)\n",
    "\n",
    "### üîê **Security and Governance**\n",
    "* [AI Governance Framework](https://www.databricks.com/blog/2023/09/14/responsible-ai-governance-databricks-lakehouse-platform.html)\n",
    "* [Model Registry for GenAI](https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html)\n",
    "* [Data Security for AI](https://docs.databricks.com/en/security/privacy/personal-data.html)\n",
    "* [Compliance and Auditing](https://docs.databricks.com/en/administration-guide/system-tables/index.html)\n",
    "\n",
    "### üí° **Community and Advanced Resources**\n",
    "* [Databricks Community - GenAI](https://community.databricks.com/s/topic/0TO5w00000094LGGAY/generative-ai)\n",
    "* [AI Research Papers on Databricks](https://www.databricks.com/research)\n",
    "* [Stack Overflow - Databricks AI](https://stackoverflow.com/questions/tagged/databricks+llm)\n",
    "* [Reddit - r/MachineLearning Databricks](https://www.reddit.com/r/MachineLearning/)\n",
    "* [Kaggle Databricks Competitions](https://www.kaggle.com/search?q=databricks)\n",
    "\n",
    "### üéØ **Industry-Specific Use Cases**\n",
    "* [Financial Services AI](https://www.databricks.com/solutions/industries/financial-services)\n",
    "* [Healthcare AI Applications](https://www.databricks.com/solutions/industries/healthcare-life-sciences)\n",
    "* [Retail and E-commerce AI](https://www.databricks.com/solutions/industries/retail)\n",
    "* [Manufacturing AI Solutions](https://www.databricks.com/solutions/industries/manufacturing)\n",
    "* [Media and Entertainment AI](https://www.databricks.com/solutions/industries/media-entertainment)\n",
    "\n",
    "### üöÄ **Advanced Topics and Research**\n",
    "* [Compound AI Systems](https://www.databricks.com/blog/2024/02/06/compound-ai-systems.html)\n",
    "* [Agent Memory and State Management](https://docs.databricks.com/en/machine-learning/feature-store/index.html)\n",
    "* [Multi-Agent Coordination](https://www.databricks.com/blog/2023/11/14/multi-agent-ai-systems-databricks.html)\n",
    "* [AI Agent Observability](https://docs.databricks.com/en/machine-learning/model-serving/troubleshooting.html)\n",
    "* [Scalable Agent Architectures](https://www.databricks.com/blog/2023/12/07/scaling-generative-ai-applications.html)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5. AgentBricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
